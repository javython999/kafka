# 1. 들어가며
## 1.1 카프카의 탄생
링크드인에서는 파편화된 데이터 수집 및 분석 아키텍처를 운영하는 데에 큰 어려움을 겪었다.
데이터를 생성하고 적재하기 위해서는 데이터를 생성하는 소스 애플리케이션과 데이터가 최종 적재되는 타깃 애플리케이션을 연결해야 한다.
초기 운영 시에는 소스 애플리케이션에서 타깃 애플리케이션으로 연동하는 소스 코드를 작성했고
아키텍처가 복잡하지 않아 운영이 힘들지 않았다.

시간이 지날 수록 아키텍처는 거대해졌고 소스 애플리케이션과 타깃 애플리케이션의 개수가 많아지면서 문제가 생겼다.
데이터를 전송하는 라인이 기하급수적으로 복잡해졌다.

링크드인의 데이터팀은 신규 시스템을 만들기로 결정했고 그 결과물이 바로 아파치 카프카다.
카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라
한 곳에 모아 처리할 수 있도록 중앙집중화했다.

## 1.2 빅데이터 파이프라인에서 카프카의 역할
> 높은 처리량

카프카는 프로듀서가 브로커로 데이터를 보낼 때와 컨슈머가 프로커로부터 데이터를 받을 때 모두 묶어서 전송한다.
많은 양의 데이터를 묶음 단위로 빠르게 배치 처리한다.
때문에 대용량의 실시간 로그데이터를 처리하는 데에 적합하다.
또한 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬 처리할 수 있다.
파티션 개수만큼 컨슈머 개수를 늘려서 동일 시간당 데이터 처리량을 늘리는 것이다.

> 확장성

데이터 파이프라인에서 데이터를 모을 때 데이터가 얼마나 들어올지는 예측하기 어렵다.
카프카는 가변적인 환경에서 안정적으로 확장 가능하도록 설계되었다.
데이터가 적을 때는 카프카 클러스터의 브로커를 최소한의 개수로 운영하다가 데이터가 많아지면
클러스터의 브로커 개수를 자연스럽게 늘려 스케일 아웃할 수 있다.
반대로 데이터 개수가 적어지고 추가 서버들이 더는 필요 없어지면 브로커 개수를 줄여 스케일 인 할 수 있다.

> 영속성

카프카는 다른 메시징 플랫폼과 다르게 전송받은 데이터를 메모리에 저장하지 않고 파일 시스템에 저장한다.
파일 시스템에 데이터를 적재하고 사용하는 것은 보편적으로 느리다고 생각하겠지만,
카프카는 운영체제 레벨에서 파일 시스템을 최대한 활요하는 방법을 적용하였다.
운영체제에서는 파일 I/O 성킁 향상을 위해 페이지 캐시 영역을 메모리에 따로 생성하여 사용한다.
페이지 캐시 메모리 영역을 사용하여 한번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하는 방식이기 때문에
카프카가 파일 시스템에 저장하고 데이터를 저장, 전송하더라도 처리량이 높은 것이다.
디스크 기반의 파일 시스템을 활용한 덕분에 브로커 애플리케이션이 장애 방생으로 인해 급작스럽게 종료되더라도
프로세스를 재시작하여 안전하게 데이터를 처리할 수 있다.

> 고가용성

3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다.
클러스터로 이루어진 카프카는 데이터의 복제를 통해 고가용성의 특징을 가지게 되었다.

## 1.3 데이터 레이크 아키텍처와 카프카의 미래
카프카의 미래에 대해 설명하려면 데이터 레이크를 구성하는 아키텍처의 역사를 알아야 한다.
데이터 레이크 아키텍처의 종류는 2가지가 있다.

1. 람다 아키텍처
2. 카파 아키텍처

람다 아키텍처는 레거시 데이터 수집 플랫폼을 개선하기 위해 구성한 아키텍처이다.
초기 플랫폼은 엔드 투 엔드 각 서비스 애플리케이션으로부터 데이터를 배치로 모았다.
데이터를 배치로 모으는 구조는 유연하지 못했으며, 실시간으로 생성되는 데이터들에 대한 인사이트를
서비스 애플리케이션에 빠르게 전달하지 못하는 단점이 있었다.
또한 원천 데이터로부터 파생된 데이터의 히스토리를 파악하기 어려웠거 계속되는 데이터의 가공으로 인해
데이터가 파편화되면서 데이터 거버넌스(데이터 표준 및 정책)를 지키기 어려웠다.

이를 해결하기 위해 기존 배치 데이터를 처리하는 부분 외에 스피드 레이어라고 불리는 실시간 데이터 ETL 작업 영역을 정의한 아키텍처를 만들었는데
이것이 람다 아키텍처이다. 람다 아키텍처는 3가지 레이어로 나뉜다.
1. 배치레이어: 배치 데이터를 모아 특정 시간, 아이밍 마다 일괄 처리한다.
2. 서빙레이어: 가공된데이터를 데이터 사용자, 서비스 애플리케이션이 사용할 수 있도록 데이터가 저장된 공간이다.
3. 스피드레이어: 서비스에서 생성되는 원천 데이터를 실시간으로 분석하는 용도로 사용한다. 배치 데이터에 비해 낮은 지연으로 분석이 필요한 경우 스피드레이어를 통해 분석한다.

데이터를 배치처리하는 레이어와 실시간 처리하는 레이어로 분리한 람다 아키텍처는 데이터 처리방식을 명확히 나눌 수 있었지만
레이어가 2개로 나뉘기 때문에 생기는 단점이 있다. 

1. 데이터를 분석, 처리하는데 필요한 로직이 2벌로 각각의 레이어에 따로 존재해야한다는 점
2. 배치 데이터와 실시간 데이터를 융합하여 처리할 때는 다소 유연하지 못한 파이프라인을 생성해야 한다는 점

이러한 람다 아키텍처의 단점을 해소하기 위해 카파 아키텍처가 제안됐다.
카파 아키텍처는 람다 아키텍처와 유사하지만 배치 레이어를 제거하고 모든 데이터를 스피드 레이어에 넣어서 처리한다는 점이 다르다.
스피드 레이어에서 데이터를 모두 처리할 수 있게 되었다. 

## 1.4 정리
카프카를 활용할 수 있는 방안은 아키텍처를 어떻게 구성하느냐에 따라 무궁무진하게 많아진다.
아키텍처 구성을 정하려면 카프카의 특징과 카프카의 동작 방식에 대해 면밀하게 알아야만한다.

--- 

# 2. 카프카 빠르게 시작해보기
## 2.1 실습용 카프카 브로커 설치
## 2.2 카프마 커맨드 라인 툴
## 2.3 정리

---

# 3. 카프카 기본 개념 설명
## 3.1 카프카 브로커, 클러스터, 주키퍼
## 3.2 토픽과 파티션
## 3.3 레코드
## 3.4 카프카 클라이언트
## 3.5 카프카 스트림즈
## 3.6 카프카 커넥트

---

# 4. 카프카 상세 개념 설명
## 4.1 토픽과 파티션
## 4.2 카프카 프로듀서
## 4.3 카프카 컨슈머
## 4.4 스프링 카프카
## 4.5 정리



